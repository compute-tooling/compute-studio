{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Developer Documentation Welcome to COMP CE's developer documentation! Publish Check out our guide for publishing on compmodels.org . API Check out our guide for using the compmodels.org API.","title":"Home"},{"location":"#developer-documentation","text":"Welcome to COMP CE's developer documentation!","title":"Developer Documentation"},{"location":"#publish","text":"Check out our guide for publishing on compmodels.org .","title":"Publish"},{"location":"#api","text":"Check out our guide for using the compmodels.org API.","title":"API"},{"location":"api/auth/","text":"Authentication API endpoints that create simulations require the user to include their API Token with their request. Here a few methods for retrieving your authentication token: COMP-Developer-ToolKit $ cdk-token --username myuser --password mypass Token: your-token-here HTTPie $ http post https://www.compmodels.org/api-token-auth/ username=hdoupe password=mypass HTTP/1.1 200 OK Allow: POST, OPTIONS { \"token\": \"Your token here\" } Python with the Requests library In [1]: import requests In [2]: resp = requests.post(\"https://www.compmodels.org/api-token-auth/\", json={\"username\": \"hdoupe\", \"password\": \"mypass\"}) In [3]: resp.json() Out[3]: {'token': 'Your token here'}","title":"Authentication"},{"location":"api/auth/#authentication","text":"API endpoints that create simulations require the user to include their API Token with their request. Here a few methods for retrieving your authentication token:","title":"Authentication"},{"location":"api/auth/#comp-developer-toolkit","text":"$ cdk-token --username myuser --password mypass Token: your-token-here","title":"COMP-Developer-ToolKit"},{"location":"api/auth/#httpie","text":"$ http post https://www.compmodels.org/api-token-auth/ username=hdoupe password=mypass HTTP/1.1 200 OK Allow: POST, OPTIONS { \"token\": \"Your token here\" }","title":"HTTPie"},{"location":"api/auth/#python-with-the-requests-library","text":"In [1]: import requests In [2]: resp = requests.post(\"https://www.compmodels.org/api-token-auth/\", json={\"username\": \"hdoupe\", \"password\": \"mypass\"}) In [3]: resp.json() Out[3]: {'token': 'Your token here'}","title":"Python with the Requests library"},{"location":"api/guide/","text":"API Guide COMP offers a REST API for creating simulations, viewing existing simulations, and viewing the input parameters for a given model. This is intended for users who would like to build applications on top of the COMP interface or create simulations programmatically. An API token is required for requests that modify data. Find out how to get your token here . More information about the data formats that are shown below can be found in the COMP publishing documentation on inputs and outputs . This guide details the COMP API endpoints and schema. A more practical Python example is also provided. /[owner]/[title]/api/v1/ Used for creating simulations. Supports POST HTTP actions. Create simulation POST hdoupe/Matchups/api/v1/ Example: { \"meta_parameters\": { \"use_full_data\": true }, \"adjustment\": { \"matchup\": { \"pitcher\": \"Max Scherzer\" } } } Response: HTTP/1.1 201 Created Allow: GET, POST, HEAD, OPTIONS { \"api_url\": \"/hdoupe/Matchups/api/v1/22\", \"creation_date\": \"2019-05-31T10:43:03.105760-05:00\", \"eta\": 0.33, \"gui_url\": \"/hdoupe/Matchups/22/\", \"inputs\": { \"adjustment\": { \"matchup\": { \"pitcher\": \"Max Scherzer\" } }, \"errors_warnings\": { \"API\": { \"errors\": {}, \"warnings\": {} }, \"GUI\": { \"errors\": {}, \"warnings\": {} }, \"matchup\": { \"errors\": {}, \"warnings\": {} } }, \"inputs_file\": null, \"meta_parameters\": { \"use_full_data\": true } }, \"model_pk\": 22, \"outputs\": null, \"traceback\": null } /[owner]/[title]/api/v1/[model_pk] Used for getting simulations. Supports GET HTTP actions. Get simulation GET /hdoupe/Matchups/api/v1/22 Response: HTTP 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"inputs\": { \"meta_parameters\": { \"use_full_data\": true }, \"adjustment\": { \"matchup\": { \"pitcher\": \"Max Scherzer\" } }, \"inputs_file\": null, \"errors_warnings\": { \"API\": { \"errors\": {}, \"warnings\": {} }, \"GUI\": { \"errors\": {}, \"warnings\": {} }, \"matchup\": { \"errors\": {}, \"warnings\": {} } } }, \"outputs\": { \"renderable\": [ { \"title\": \"Max Scherzer v. All batters\", \"media_type\": \"bokeh\", \"data\": { \"html\": \"html here\", \"javascript\": \"javascript here\" } }, { \"title\": \"Max Scherzer v. Chipper Jones\", \"media_type\": \"bokeh\", \"data\": { \"html\": \"html here\", \"javascript\": \"javascript here\" } } ], \"downloadable\": [ { \"title\": \"Max Scherzer v. All batters\", \"media_type\": \"CSV\", \"data\": \"csv here\" }, { \"title\": \"Max Scherzer v. Chipper Jones\", \"media_type\": \"CSV\", \"data\": \"csv here\" } ] }, \"traceback\": null, \"creation_date\": \"2019-05-31T11:41:22.211492-05:00\", \"api_url\": \"/hdoupe/Matchups/api/v1/23\", \"gui_url\": \"/hdoupe/Matchups/23/\", \"eta\": 0.0, \"model_pk\": 23 } /[owner]/[title]/api/v1/inputs/ Used for viewing the inputs for a given model. Supports GET and POST HTTP actions. View inputs: GET hdoupe/Matchups/api/v1/inputs/ Response: HTTP 200 OK Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"meta_parameters\": { \"use_full_data\": { \"type\": \"bool\", \"title\": \"Use Full Data\", \"value\": [ { \"value\": true } ], \"validators\": { \"choice\": { \"choices\": [ true, false ] } }, \"description\": \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\", \"number_dims\": 0 } }, \"model_parameters\": { \"matchup\": { \"start_date\": { \"type\": \"date\", \"section_1\": \"Date\", \"title\": \"Start Date\", \"value\": [ { \"value\": \"2008-01-01\", \"use_full_data\": true } ], \"validators\": { \"date_range\": { \"max\": \"end_date\", \"min\": \"2008-01-01\" } }, \"description\": \"Date to start pulling statcast information\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"number_dims\": 0 }, \"pitcher\": { \"type\": \"str\", \"section_1\": \"Parameters\", \"title\": \"Pitcher Name\", \"value\": [ { \"value\": \"Clayton Kershaw\", \"use_full_data\": true } ], \"validators\": { \"choice\": { \"choices\": [ \"A. J. Achter\", \"A. J. Burnett\", \"A. J. Cole\", \"A. J. Ellis\", \"A. J. Griffin\", \"A. J. Jimenez\", \"A. J. Minter\", \"A. J. Morris\", \"A. J. Murray\", \"A. J. Pierzynski\", \"A. J. Pollock\", \"A. J. Reed\", \"A. J. Schugel\", \"AJ Ramos\", \"Aaron Altherr\", \"Aaron Barrett\", ... Update with meta parameters POST /hdoupe/Matchups/api/v1/inputs/ Example: { \"meta_parameters\": {\"use_full_data\": true} } Response: HTTP 200 OK Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"meta_parameters\": { \"use_full_data\": { \"type\": \"bool\", \"title\": \"Use Full Data\", \"value\": [ { \"value\": false } ], \"validators\": { \"choice\": { \"choices\": [ true, false ] } }, \"description\": \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\", \"number_dims\": 0 } }, \"model_parameters\": { \"matchup\": { \"start_date\": { \"type\": \"date\", \"section_1\": \"Date\", \"title\": \"Start Date\", \"value\": [ { \"value\": \"2018-01-01\", \"use_full_data\": false } ], \"validators\": { \"date_range\": { \"max\": \"end_date\", \"min\": \"2008-01-01\" } }, \"description\": \"Date to start pulling statcast information\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"number_dims\": 0 }, \"pitcher\": { \"type\": \"str\", \"section_1\": \"Parameters\", \"title\": \"Pitcher Name\", \"value\": [ { \"value\": \"Jacob deGrom\", \"use_full_data\": false } ], \"validators\": { \"choice\": { \"choices\": [ \"A. J. Achter\", \"A. J. Burnett\", \"A. J. Cole\", \"A. J. Ellis\", \"A. J. Griffin\", \"A. J. Jimenez\", \"A. J. Minter\", \"A. J. Morris\", \"A. J. Murray\", \"A. J. Pierzynski\", ...","title":"Guide"},{"location":"api/guide/#api-guide","text":"COMP offers a REST API for creating simulations, viewing existing simulations, and viewing the input parameters for a given model. This is intended for users who would like to build applications on top of the COMP interface or create simulations programmatically. An API token is required for requests that modify data. Find out how to get your token here . More information about the data formats that are shown below can be found in the COMP publishing documentation on inputs and outputs . This guide details the COMP API endpoints and schema. A more practical Python example is also provided.","title":"API Guide"},{"location":"api/guide/#ownertitleapiv1","text":"Used for creating simulations. Supports POST HTTP actions.","title":"/[owner]/[title]/api/v1/"},{"location":"api/guide/#create-simulation","text":"POST hdoupe/Matchups/api/v1/ Example: { \"meta_parameters\": { \"use_full_data\": true }, \"adjustment\": { \"matchup\": { \"pitcher\": \"Max Scherzer\" } } } Response: HTTP/1.1 201 Created Allow: GET, POST, HEAD, OPTIONS { \"api_url\": \"/hdoupe/Matchups/api/v1/22\", \"creation_date\": \"2019-05-31T10:43:03.105760-05:00\", \"eta\": 0.33, \"gui_url\": \"/hdoupe/Matchups/22/\", \"inputs\": { \"adjustment\": { \"matchup\": { \"pitcher\": \"Max Scherzer\" } }, \"errors_warnings\": { \"API\": { \"errors\": {}, \"warnings\": {} }, \"GUI\": { \"errors\": {}, \"warnings\": {} }, \"matchup\": { \"errors\": {}, \"warnings\": {} } }, \"inputs_file\": null, \"meta_parameters\": { \"use_full_data\": true } }, \"model_pk\": 22, \"outputs\": null, \"traceback\": null }","title":"Create simulation"},{"location":"api/guide/#ownertitleapiv1model_pk","text":"Used for getting simulations. Supports GET HTTP actions.","title":"/[owner]/[title]/api/v1/[model_pk]"},{"location":"api/guide/#get-simulation","text":"GET /hdoupe/Matchups/api/v1/22 Response: HTTP 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"inputs\": { \"meta_parameters\": { \"use_full_data\": true }, \"adjustment\": { \"matchup\": { \"pitcher\": \"Max Scherzer\" } }, \"inputs_file\": null, \"errors_warnings\": { \"API\": { \"errors\": {}, \"warnings\": {} }, \"GUI\": { \"errors\": {}, \"warnings\": {} }, \"matchup\": { \"errors\": {}, \"warnings\": {} } } }, \"outputs\": { \"renderable\": [ { \"title\": \"Max Scherzer v. All batters\", \"media_type\": \"bokeh\", \"data\": { \"html\": \"html here\", \"javascript\": \"javascript here\" } }, { \"title\": \"Max Scherzer v. Chipper Jones\", \"media_type\": \"bokeh\", \"data\": { \"html\": \"html here\", \"javascript\": \"javascript here\" } } ], \"downloadable\": [ { \"title\": \"Max Scherzer v. All batters\", \"media_type\": \"CSV\", \"data\": \"csv here\" }, { \"title\": \"Max Scherzer v. Chipper Jones\", \"media_type\": \"CSV\", \"data\": \"csv here\" } ] }, \"traceback\": null, \"creation_date\": \"2019-05-31T11:41:22.211492-05:00\", \"api_url\": \"/hdoupe/Matchups/api/v1/23\", \"gui_url\": \"/hdoupe/Matchups/23/\", \"eta\": 0.0, \"model_pk\": 23 }","title":"Get simulation"},{"location":"api/guide/#ownertitleapiv1inputs","text":"Used for viewing the inputs for a given model. Supports GET and POST HTTP actions.","title":"/[owner]/[title]/api/v1/inputs/"},{"location":"api/guide/#view-inputs","text":"GET hdoupe/Matchups/api/v1/inputs/ Response: HTTP 200 OK Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"meta_parameters\": { \"use_full_data\": { \"type\": \"bool\", \"title\": \"Use Full Data\", \"value\": [ { \"value\": true } ], \"validators\": { \"choice\": { \"choices\": [ true, false ] } }, \"description\": \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\", \"number_dims\": 0 } }, \"model_parameters\": { \"matchup\": { \"start_date\": { \"type\": \"date\", \"section_1\": \"Date\", \"title\": \"Start Date\", \"value\": [ { \"value\": \"2008-01-01\", \"use_full_data\": true } ], \"validators\": { \"date_range\": { \"max\": \"end_date\", \"min\": \"2008-01-01\" } }, \"description\": \"Date to start pulling statcast information\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"number_dims\": 0 }, \"pitcher\": { \"type\": \"str\", \"section_1\": \"Parameters\", \"title\": \"Pitcher Name\", \"value\": [ { \"value\": \"Clayton Kershaw\", \"use_full_data\": true } ], \"validators\": { \"choice\": { \"choices\": [ \"A. J. Achter\", \"A. J. Burnett\", \"A. J. Cole\", \"A. J. Ellis\", \"A. J. Griffin\", \"A. J. Jimenez\", \"A. J. Minter\", \"A. J. Morris\", \"A. J. Murray\", \"A. J. Pierzynski\", \"A. J. Pollock\", \"A. J. Reed\", \"A. J. Schugel\", \"AJ Ramos\", \"Aaron Altherr\", \"Aaron Barrett\", ...","title":"View inputs:"},{"location":"api/guide/#update-with-meta-parameters","text":"POST /hdoupe/Matchups/api/v1/inputs/ Example: { \"meta_parameters\": {\"use_full_data\": true} } Response: HTTP 200 OK Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"meta_parameters\": { \"use_full_data\": { \"type\": \"bool\", \"title\": \"Use Full Data\", \"value\": [ { \"value\": false } ], \"validators\": { \"choice\": { \"choices\": [ true, false ] } }, \"description\": \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\", \"number_dims\": 0 } }, \"model_parameters\": { \"matchup\": { \"start_date\": { \"type\": \"date\", \"section_1\": \"Date\", \"title\": \"Start Date\", \"value\": [ { \"value\": \"2018-01-01\", \"use_full_data\": false } ], \"validators\": { \"date_range\": { \"max\": \"end_date\", \"min\": \"2008-01-01\" } }, \"description\": \"Date to start pulling statcast information\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"number_dims\": 0 }, \"pitcher\": { \"type\": \"str\", \"section_1\": \"Parameters\", \"title\": \"Pitcher Name\", \"value\": [ { \"value\": \"Jacob deGrom\", \"use_full_data\": false } ], \"validators\": { \"choice\": { \"choices\": [ \"A. J. Achter\", \"A. J. Burnett\", \"A. J. Cole\", \"A. J. Ellis\", \"A. J. Griffin\", \"A. J. Jimenez\", \"A. J. Minter\", \"A. J. Morris\", \"A. J. Murray\", \"A. J. Pierzynski\", ...","title":"Update with meta parameters"},{"location":"api/python/","text":"Python The COMP REST API can easily be wrapped with a Python class to provide a more intuitive way to use the API: api = API(\"PSLmodels\", \"Tax-Brain\", api_token=\"your token\") res = api.create( meta_parameters={ \"use_full_sample\": False, \"data_source\": \"CPS\" }, adjustment={ \"policy\": { \"II_em\": [{\"year\": 2020, \"value\": 5000}] } } ) # output: # {'inputs': {'meta_parameters': {'year': 2020, # 'data_source': 'PUF', # 'use_full_sample': False}, # 'adjustment': {'policy': {'II_em': [{'year': 2020, 'value': 5000}]}, # 'behavior': {}}, # 'inputs_file': {'policy': {'II_em': {'2020': 5000}}, 'behavior': {}}, # 'errors_warnings': {'policy': {'errors': {}, 'warnings': {}}, # 'behavior': {'errors': {}, 'warnings': {}}, # 'GUI': {'errors': {}, 'warnings': {}}, # 'API': {'errors': {}, 'warnings': {}}}}, # 'outputs': None, # 'traceback': None, # 'creation_date': '2019-06-04T08:47:30.287598-05:00', # 'api_url': '/PSLmodels/Tax-Brain/api/v1/40754/', # 'gui_url': '/PSLmodels/Tax-Brain/40754/', # 'eta': 5.0, # 'model_pk': 40754} Retrieve the result as a Pandas DataFrame: result = api.results(res[\"model_pk\"]) result[\"Total Liabilities Change by Calendar Year (Billions).csv\"] # output: # Unnamed: 0 2020 # 0 Individual Income Tax Liability Change $-168.21 # 1 Payroll Tax Liability Change $0.00 # 2 Combined Payroll and Individual Income Tax Lia... $-168.21 View the model's inputs: api.inputs() # output: # {'meta_parameters': {'year': {'validators': {'choice': {'choices': [2013, # 2014, # 2015, # 2016, # 2017, # 2018, # 2019, # 2020, # 2021, # 2022, # 2023, # 2024, # 2025, # 2026, # 2027, # 2028]}}, # 'description': 'Year for parameters.', # 'title': 'Start Year', # 'number_dims': 0, # 'type': 'int', # 'value': [{'value': 2019}]}, # 'data_source': {'validators': {'choice': {'choices': ['PUF', 'CPS']}}, # 'description': 'Data source can be PUF or CPS', # 'title': 'Data Source', # 'number_dims': 0, # 'type': 'str', # 'value': [{'value': 'PUF'}]}, # 'use_full_sample': {'validators': {'choice': {'choices': [True, False]}}, # 'description': 'Use entire data set or a 2% sample.', # 'title': 'Use Full Sample', # 'number_dims': 0, # 'type': 'bool', # 'value': [{'value': True}]}}, # 'model_parameters': {'policy': {'CPI_offset': {'validators': {'range': {'min': -0.005, # 'max': 0.005}}, # 'section_2': 'Offsets', # 'section_1': 'Parameter Indexing', # 'description': 'Values are zero before 2017; reforms that introduce indexing with chained CPI would have values around -0.0025 beginning in the year before the first year policy parameters will have values computed with chained CPI.', # 'title': 'Decimal offset ADDED to unchained CPI to get parameter indexing rate', # 'number_dims': 0, # 'notes': \"See April 2013 CBO report entitled 'What Would Be the Effect on the Deficit of Using the Chained CPI to Index Benefit Programs and the Tax Code?', which includes this: 'The chained CPI grows more slowly than the traditional CPI does: an average of about 0.25 percentage points more slowly per year over the past decade.' <https://www.cbo.gov/publication/44089>\", # 'type': 'float', # 'value': [{'year': 2019, 'value': -0.0025}]}, # 'FICA_ss_trt': {'validators': {'range': {'min': 0, 'max': 1}}, # 'section_2': 'Social Security FICA', # 'section_1': 'Payroll Taxes', # 'description': 'Social Security FICA rate, including both employer and employee.', # 'title': 'Social Security payroll tax rate', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 0.124}]}, # 'SS_Earnings_c': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': True, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings below this amount are subjected to Social Security (OASDI) payroll tax.', # 'title': 'Maximum taxable earnings (MTE) for Social Security', # 'number_dims': 0, # 'notes': 'This parameter is indexed by the rate of growth in average wages, not by the price inflation rate.', # 'type': 'float', # 'value': [{'year': 2019, 'value': 133048.08}]}, # 'SS_Earnings_thd': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': False, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings above this threshold are subjected to Social Security (OASDI) payroll tax, in addition to earnings below the maximum taxable earnings threshold.', # 'title': 'Additional Taxable Earnings Threshold for Social Security', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 9e+99}]}, # # ... API implementation: from io import StringIO import time import requests import pandas as pd class APIException(Exception): pass class API: host = \"https://www.compmodels.org\" def __init__(self, owner, title, api_token=None): self.owner = owner self.title = title api_token = self.get_token(api_token) self.auth_header = { \"Authorization\": f\"Token {api_token}\" } self.sim_url = f\"{self.host}/{owner}/{title}/api/v1/\" self.inputs_url = f\"{self.host}/{owner}/{title}/api/v1/inputs/\" def inputs(self, meta_parameters: dict = None): meta_parameters = meta_parameters or {} if not meta_parameters: resp = requests.get(self.inputs_url) else: resp = requests.post( self.inputs_url, json=meta_parameters, ) if resp.status_code == 200: return resp.json() raise APIException(resp.text) def create(self, adjustment: dict = None, meta_parameters: dict = None): adjustment = adjustment or {} meta_parameters = meta_parameters or {} resp = requests.post( self.sim_url, json={ \"adjustment\": adjustment, \"meta_parameters\": meta_parameters }, headers=self.auth_header ) if resp.status_code == 201: return resp.json() raise APIException(resp.text) def detail(self, model_pk): while True: resp = requests.get(f\"{self.sim_url}{model_pk}/\") if resp.status_code == 202: pass elif resp.status_code == 200: return resp.json() else: raise APIException(resp.text) time.sleep(20) def results(self, model_pk): result = self.detail(model_pk) res = {} for output in result[\"outputs\"][\"downloadable\"]: if output[\"media_type\"] == \"CSV\": res[output[\"title\"]] = pd.read_csv( StringIO(output[\"data\"]) ) else: print(f'{output[\"media_type\"]} not implemented yet') return res def get_token(self, api_token): if api_token: return api_token elif os.environ.get(\"COMP_API_TOKEN\", None) is not None: return os.environ[\"COMP_API_TOKEN\"] elif os.path.exists(\"~/.comp-api-token\"): with open(\"~/.comp-api-token\", \"r\") as f: return f.read().strip() else: raise APIException( \"API token not found. It can be passed as an argument to \" \"this class, as an environment variable, or read from \" \"~/.comp-api-token\" )","title":"Python"},{"location":"api/python/#python","text":"The COMP REST API can easily be wrapped with a Python class to provide a more intuitive way to use the API: api = API(\"PSLmodels\", \"Tax-Brain\", api_token=\"your token\") res = api.create( meta_parameters={ \"use_full_sample\": False, \"data_source\": \"CPS\" }, adjustment={ \"policy\": { \"II_em\": [{\"year\": 2020, \"value\": 5000}] } } ) # output: # {'inputs': {'meta_parameters': {'year': 2020, # 'data_source': 'PUF', # 'use_full_sample': False}, # 'adjustment': {'policy': {'II_em': [{'year': 2020, 'value': 5000}]}, # 'behavior': {}}, # 'inputs_file': {'policy': {'II_em': {'2020': 5000}}, 'behavior': {}}, # 'errors_warnings': {'policy': {'errors': {}, 'warnings': {}}, # 'behavior': {'errors': {}, 'warnings': {}}, # 'GUI': {'errors': {}, 'warnings': {}}, # 'API': {'errors': {}, 'warnings': {}}}}, # 'outputs': None, # 'traceback': None, # 'creation_date': '2019-06-04T08:47:30.287598-05:00', # 'api_url': '/PSLmodels/Tax-Brain/api/v1/40754/', # 'gui_url': '/PSLmodels/Tax-Brain/40754/', # 'eta': 5.0, # 'model_pk': 40754} Retrieve the result as a Pandas DataFrame: result = api.results(res[\"model_pk\"]) result[\"Total Liabilities Change by Calendar Year (Billions).csv\"] # output: # Unnamed: 0 2020 # 0 Individual Income Tax Liability Change $-168.21 # 1 Payroll Tax Liability Change $0.00 # 2 Combined Payroll and Individual Income Tax Lia... $-168.21 View the model's inputs: api.inputs() # output: # {'meta_parameters': {'year': {'validators': {'choice': {'choices': [2013, # 2014, # 2015, # 2016, # 2017, # 2018, # 2019, # 2020, # 2021, # 2022, # 2023, # 2024, # 2025, # 2026, # 2027, # 2028]}}, # 'description': 'Year for parameters.', # 'title': 'Start Year', # 'number_dims': 0, # 'type': 'int', # 'value': [{'value': 2019}]}, # 'data_source': {'validators': {'choice': {'choices': ['PUF', 'CPS']}}, # 'description': 'Data source can be PUF or CPS', # 'title': 'Data Source', # 'number_dims': 0, # 'type': 'str', # 'value': [{'value': 'PUF'}]}, # 'use_full_sample': {'validators': {'choice': {'choices': [True, False]}}, # 'description': 'Use entire data set or a 2% sample.', # 'title': 'Use Full Sample', # 'number_dims': 0, # 'type': 'bool', # 'value': [{'value': True}]}}, # 'model_parameters': {'policy': {'CPI_offset': {'validators': {'range': {'min': -0.005, # 'max': 0.005}}, # 'section_2': 'Offsets', # 'section_1': 'Parameter Indexing', # 'description': 'Values are zero before 2017; reforms that introduce indexing with chained CPI would have values around -0.0025 beginning in the year before the first year policy parameters will have values computed with chained CPI.', # 'title': 'Decimal offset ADDED to unchained CPI to get parameter indexing rate', # 'number_dims': 0, # 'notes': \"See April 2013 CBO report entitled 'What Would Be the Effect on the Deficit of Using the Chained CPI to Index Benefit Programs and the Tax Code?', which includes this: 'The chained CPI grows more slowly than the traditional CPI does: an average of about 0.25 percentage points more slowly per year over the past decade.' <https://www.cbo.gov/publication/44089>\", # 'type': 'float', # 'value': [{'year': 2019, 'value': -0.0025}]}, # 'FICA_ss_trt': {'validators': {'range': {'min': 0, 'max': 1}}, # 'section_2': 'Social Security FICA', # 'section_1': 'Payroll Taxes', # 'description': 'Social Security FICA rate, including both employer and employee.', # 'title': 'Social Security payroll tax rate', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 0.124}]}, # 'SS_Earnings_c': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': True, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings below this amount are subjected to Social Security (OASDI) payroll tax.', # 'title': 'Maximum taxable earnings (MTE) for Social Security', # 'number_dims': 0, # 'notes': 'This parameter is indexed by the rate of growth in average wages, not by the price inflation rate.', # 'type': 'float', # 'value': [{'year': 2019, 'value': 133048.08}]}, # 'SS_Earnings_thd': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': False, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings above this threshold are subjected to Social Security (OASDI) payroll tax, in addition to earnings below the maximum taxable earnings threshold.', # 'title': 'Additional Taxable Earnings Threshold for Social Security', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 9e+99}]}, # # ...","title":"Python"},{"location":"api/python/#api-implementation","text":"from io import StringIO import time import requests import pandas as pd class APIException(Exception): pass class API: host = \"https://www.compmodels.org\" def __init__(self, owner, title, api_token=None): self.owner = owner self.title = title api_token = self.get_token(api_token) self.auth_header = { \"Authorization\": f\"Token {api_token}\" } self.sim_url = f\"{self.host}/{owner}/{title}/api/v1/\" self.inputs_url = f\"{self.host}/{owner}/{title}/api/v1/inputs/\" def inputs(self, meta_parameters: dict = None): meta_parameters = meta_parameters or {} if not meta_parameters: resp = requests.get(self.inputs_url) else: resp = requests.post( self.inputs_url, json=meta_parameters, ) if resp.status_code == 200: return resp.json() raise APIException(resp.text) def create(self, adjustment: dict = None, meta_parameters: dict = None): adjustment = adjustment or {} meta_parameters = meta_parameters or {} resp = requests.post( self.sim_url, json={ \"adjustment\": adjustment, \"meta_parameters\": meta_parameters }, headers=self.auth_header ) if resp.status_code == 201: return resp.json() raise APIException(resp.text) def detail(self, model_pk): while True: resp = requests.get(f\"{self.sim_url}{model_pk}/\") if resp.status_code == 202: pass elif resp.status_code == 200: return resp.json() else: raise APIException(resp.text) time.sleep(20) def results(self, model_pk): result = self.detail(model_pk) res = {} for output in result[\"outputs\"][\"downloadable\"]: if output[\"media_type\"] == \"CSV\": res[output[\"title\"]] = pd.read_csv( StringIO(output[\"data\"]) ) else: print(f'{output[\"media_type\"]} not implemented yet') return res def get_token(self, api_token): if api_token: return api_token elif os.environ.get(\"COMP_API_TOKEN\", None) is not None: return os.environ[\"COMP_API_TOKEN\"] elif os.path.exists(\"~/.comp-api-token\"): with open(\"~/.comp-api-token\", \"r\") as f: return f.read().strip() else: raise APIException( \"API token not found. It can be passed as an argument to \" \"this class, as an environment variable, or read from \" \"~/.comp-api-token\" )","title":"API implementation:"},{"location":"publish/environment/","text":"Model Environment COMP runs each project in its own Docker container. Miniconda3 is used as the base image. This means that conda is installed by default. Thus, all packages available through the conda package manager can easily be installed. Include installation instructions in your email to Hank, and he will add them to the project's Dockerfile . If you are inclined, you will have access to this Dockerfile and will be able to build the Docker image and experiment with it. The installation instructions for the matchups project are simply a bash script: conda install pandas pyarrow pip install pybaseball matchups","title":"Environment"},{"location":"publish/environment/#model-environment","text":"COMP runs each project in its own Docker container. Miniconda3 is used as the base image. This means that conda is installed by default. Thus, all packages available through the conda package manager can easily be installed. Include installation instructions in your email to Hank, and he will add them to the project's Dockerfile . If you are inclined, you will have access to this Dockerfile and will be able to build the Docker image and experiment with it. The installation instructions for the matchups project are simply a bash script: conda install pandas pyarrow pip install pybaseball matchups","title":"Model Environment"},{"location":"publish/functions/","text":"Python functions The modeling project must provide a Python function for each of the following tasks: Model Parameters : Get the default Model Parameters and their meta data. Parse user adjustments : Do model-specific formatting and validation on user adjustments. Run simulation : Submit the user adjustments (or none) to the model to run the simulation. Once you've skimmed the criteria below, you can develop your functions against the compdevkit automated testing suite. Model Parameters Accepts Meta Parameters, if they are being utilized. Returns data in the form specified in the inputs page . Python Example : import matchups def get_inputs(meta_params_dict): meta_params = MetaParams() meta_params.adjust(meta_params_dict) params = MatchupsParams() spec = params.specification( meta_data=True, use_full_data=meta_params.use_full_data.tolist() ) return meta_params.specification(meta_data=True), {\"matchup\": spec} Here's what you get after filling in this function: Validate user adjustments Accepts parsed user adjustments, separated by each major section. Returns warnings/errors (if any). COMP will provide parsed user adjustments of the form: { \"matchup\": { \"start_date\": [{\"value\": \"2012-08-01\"}], \"end_date\": [{\"value\": \"2012-09-01\"}], \"pitcher\": [{\"value\": \"Not a Real Pitcher\"}], } } The function should return: Warnings/Errors: { \"matchup\": { \"errors\": { \"pitcher\": ['Pitcher \"Not a Real Pitcher\" not allowed'] }, \"warnings\": {} } } Python : import matchups def validate_inputs(meta_param_dict, adjustment, errors_warnings): # matchups doesn't look at meta_param_dict for validating inputs. params = MatchupsParams() params.adjust(adjustment[\"matchup\"], raise_errors=False) errors_warnings[\"matchup\"][\"errors\"].update(params.errors) return errors_warnings Here's what you get after filling in this function: Run simulation Accepts Meta Parameters values and model parameters. Returns outputs as specified in the outputs page COMP submits the model's meta parameters and the parsed and formatted user adjustments: { \"meta_params\": {}, \"model_params\": { \"some_major_section\": {}, \"another_major_section\": {} } } Python Example : import matchups def get_matchup(meta_param_dict, adjustment): result = matchups.get_matchup(meta_param_dict, adjustment) return result Here's what you get after filling in this function:","title":"Functions"},{"location":"publish/functions/#python-functions","text":"The modeling project must provide a Python function for each of the following tasks: Model Parameters : Get the default Model Parameters and their meta data. Parse user adjustments : Do model-specific formatting and validation on user adjustments. Run simulation : Submit the user adjustments (or none) to the model to run the simulation. Once you've skimmed the criteria below, you can develop your functions against the compdevkit automated testing suite.","title":"Python functions"},{"location":"publish/functions/#model-parameters","text":"Accepts Meta Parameters, if they are being utilized. Returns data in the form specified in the inputs page . Python Example : import matchups def get_inputs(meta_params_dict): meta_params = MetaParams() meta_params.adjust(meta_params_dict) params = MatchupsParams() spec = params.specification( meta_data=True, use_full_data=meta_params.use_full_data.tolist() ) return meta_params.specification(meta_data=True), {\"matchup\": spec} Here's what you get after filling in this function:","title":"Model Parameters"},{"location":"publish/functions/#validate-user-adjustments","text":"Accepts parsed user adjustments, separated by each major section. Returns warnings/errors (if any). COMP will provide parsed user adjustments of the form: { \"matchup\": { \"start_date\": [{\"value\": \"2012-08-01\"}], \"end_date\": [{\"value\": \"2012-09-01\"}], \"pitcher\": [{\"value\": \"Not a Real Pitcher\"}], } } The function should return: Warnings/Errors: { \"matchup\": { \"errors\": { \"pitcher\": ['Pitcher \"Not a Real Pitcher\" not allowed'] }, \"warnings\": {} } } Python : import matchups def validate_inputs(meta_param_dict, adjustment, errors_warnings): # matchups doesn't look at meta_param_dict for validating inputs. params = MatchupsParams() params.adjust(adjustment[\"matchup\"], raise_errors=False) errors_warnings[\"matchup\"][\"errors\"].update(params.errors) return errors_warnings Here's what you get after filling in this function:","title":"Validate user adjustments"},{"location":"publish/functions/#run-simulation","text":"Accepts Meta Parameters values and model parameters. Returns outputs as specified in the outputs page COMP submits the model's meta parameters and the parsed and formatted user adjustments: { \"meta_params\": {}, \"model_params\": { \"some_major_section\": {}, \"another_major_section\": {} } } Python Example : import matchups def get_matchup(meta_param_dict, adjustment): result = matchups.get_matchup(meta_param_dict, adjustment) return result Here's what you get after filling in this function:","title":"Run simulation"},{"location":"publish/guide/","text":"Publishing on COMP This guide describes how to publish a model on COMP. The COMP framework depends on model interfaces meeting several COMP criteria, and we walk you through how to meet those criteria, either by modifying your model's interface or building a new wrapper interface around your model. The great part is that you don't have to deal with any web technology to build your COMP app. If you have any questions as you proceed through this guide, send Hank an email at henrymdoupe@gmail.com. The documentation is split into three parts. The first part documents the inputs and outputs JSON schemas that your model will need to adopt for COMP to be able to generate input forms representing your model's default specification, validate user adjustments, and display model outputs. The second part documents the python functions that will be used by COMP to get data from and submit data to your model. The third part is a publish form that asks you to provide a title and overview for your new COMP app, code snippets for the three python functions, and information describing your app's resource requirements and installation directions. If you would like to see a publishing template that has already been completed, you can view the Matchups template here . Once you've submitted the publishing form, Hank will review it and get back to you within 24 hours to inform you whether the model is ready to be published or if there are criteria that have not been satisfied. Your model will be deployed to COMP once it has met all of the critera. You will have the opportunity to test it out after it has been deployed.","title":"Guide"},{"location":"publish/guide/#publishing-on-comp","text":"This guide describes how to publish a model on COMP. The COMP framework depends on model interfaces meeting several COMP criteria, and we walk you through how to meet those criteria, either by modifying your model's interface or building a new wrapper interface around your model. The great part is that you don't have to deal with any web technology to build your COMP app. If you have any questions as you proceed through this guide, send Hank an email at henrymdoupe@gmail.com. The documentation is split into three parts. The first part documents the inputs and outputs JSON schemas that your model will need to adopt for COMP to be able to generate input forms representing your model's default specification, validate user adjustments, and display model outputs. The second part documents the python functions that will be used by COMP to get data from and submit data to your model. The third part is a publish form that asks you to provide a title and overview for your new COMP app, code snippets for the three python functions, and information describing your app's resource requirements and installation directions. If you would like to see a publishing template that has already been completed, you can view the Matchups template here . Once you've submitted the publishing form, Hank will review it and get back to you within 24 hours to inform you whether the model is ready to be published or if there are criteria that have not been satisfied. Your model will be deployed to COMP once it has met all of the critera. You will have the opportunity to test it out after it has been deployed.","title":"Publishing on COMP"},{"location":"publish/inputs/","text":"Inputs COMP uses the ParamTools inputs format for building its GUI. ParamTools also offers functionality for updating parameter values and validating the new values. Check out the ParamTools documentation for more information on how to create your configuration files. COMP requires two typs of inputs: meta parameters and model parameters. First, what are meta parameters ? Meta parameters control the default parameters. If the value of a parameter depends on the current year, then the user will need to set the current year via a meta parameter before they can view the parameter's default value and update it. Meta Parameters For example, the meta parameters for PSLmodels/Tax-Brain are defined like this: { \"start_year\": { \"title\": \"Start Year\", \"description\": \"Year for parameters.\", \"type\": \"int\", \"value\": 2019, \"validators\": {\"range\": {\"min\": 2019, \"max\": 2027}} }, \"data_source\": { \"title\": \"Data Source\", \"description\": \"Data source can be PUF or CPS\", \"type\": \"str\", \"value\": \"PUF\", \"validators\": {\"choice\": {\"choices\": [\"PUF\", \"CPS\"]}} }, \"use_full_sample\": { \"title\": \"Use Full Sample\", \"description\": \"Use entire data set or a 2% sample.\", \"type\": \"str\", \"value\": true, } } COMP uses this information to build a set of controls that dictate which values of the default model parameters are shown: Default Parameters The GUI is built directly from the default parameters. Here's an example using a subset of the inputs from hdoupe/Matchups : { \"schema\": { \"labels\": { \"use_full_data\": {\"type\": \"bool\", \"validators\": {}} }, \"additional_parameters\": { \"section_1\": {\"type\": \"str\", \"number_dims\": 0}, \"section_2\": {\"type\": \"str\", \"number_dims\": 0} } }, \"start_date\": { \"title\": \"Start Date\", \"description\": \"Date to start pulling statcast information\", \"section_1\": \"Date\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"type\": \"date\", \"value\": [ {\"use_full_data\": true, \"value\": \"2008-01-01\"}, {\"use_full_data\": false, \"value\": \"2018-01-01\"} ], \"validators\": {\"date_range\": {\"min\": \"2008-01-01\", \"max\": \"end_date\"}} }, \"pitcher\": { \"title\": \"Pitcher Name\", \"description\": \"Name of pitcher to pull data on\", \"section_1\": \"Parameters\", \"section_2\": \"Pitcher\", \"type\": \"str\", \"value\": \"Clayton Kershaw\", \"validators\": { \"choice\": { \"choices\": [\"Clayton Kershaw\", \"Jacob deGrom\", \"Justin Verlander\"] } } } } COMP builds the model parameter GUI directly from this data:","title":"Inputs"},{"location":"publish/inputs/#inputs","text":"COMP uses the ParamTools inputs format for building its GUI. ParamTools also offers functionality for updating parameter values and validating the new values. Check out the ParamTools documentation for more information on how to create your configuration files. COMP requires two typs of inputs: meta parameters and model parameters. First, what are meta parameters ? Meta parameters control the default parameters. If the value of a parameter depends on the current year, then the user will need to set the current year via a meta parameter before they can view the parameter's default value and update it.","title":"Inputs"},{"location":"publish/inputs/#meta-parameters","text":"For example, the meta parameters for PSLmodels/Tax-Brain are defined like this: { \"start_year\": { \"title\": \"Start Year\", \"description\": \"Year for parameters.\", \"type\": \"int\", \"value\": 2019, \"validators\": {\"range\": {\"min\": 2019, \"max\": 2027}} }, \"data_source\": { \"title\": \"Data Source\", \"description\": \"Data source can be PUF or CPS\", \"type\": \"str\", \"value\": \"PUF\", \"validators\": {\"choice\": {\"choices\": [\"PUF\", \"CPS\"]}} }, \"use_full_sample\": { \"title\": \"Use Full Sample\", \"description\": \"Use entire data set or a 2% sample.\", \"type\": \"str\", \"value\": true, } } COMP uses this information to build a set of controls that dictate which values of the default model parameters are shown:","title":"Meta Parameters"},{"location":"publish/inputs/#default-parameters","text":"The GUI is built directly from the default parameters. Here's an example using a subset of the inputs from hdoupe/Matchups : { \"schema\": { \"labels\": { \"use_full_data\": {\"type\": \"bool\", \"validators\": {}} }, \"additional_parameters\": { \"section_1\": {\"type\": \"str\", \"number_dims\": 0}, \"section_2\": {\"type\": \"str\", \"number_dims\": 0} } }, \"start_date\": { \"title\": \"Start Date\", \"description\": \"Date to start pulling statcast information\", \"section_1\": \"Date\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"type\": \"date\", \"value\": [ {\"use_full_data\": true, \"value\": \"2008-01-01\"}, {\"use_full_data\": false, \"value\": \"2018-01-01\"} ], \"validators\": {\"date_range\": {\"min\": \"2008-01-01\", \"max\": \"end_date\"}} }, \"pitcher\": { \"title\": \"Pitcher Name\", \"description\": \"Name of pitcher to pull data on\", \"section_1\": \"Parameters\", \"section_2\": \"Pitcher\", \"type\": \"str\", \"value\": \"Clayton Kershaw\", \"validators\": { \"choice\": { \"choices\": [\"Clayton Kershaw\", \"Jacob deGrom\", \"Justin Verlander\"] } } } } COMP builds the model parameter GUI directly from this data:","title":"Default Parameters"},{"location":"publish/outputs/","text":"Outputs Projects should return outputs that are in the following format: { \"renderable\": [ { \"media_type\": \"PNG\", \"title\": \"My PNG\", \"data\": \"picture bytes here...\" } ], \"downloadable\": [ { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": \"comma,sep,values\\n\" } ] } There are two categories of outputs: \"renderable\" and \"downloadable.\" Renderable outputs will be displayed on the outputs page while downloadable outputs are saved by the user as a zipfile. These categories are represented as the two top-level members in the JSON structure above. They point to a List of Output Objects . Each Output Object has three members: media_type , title , and data . Supported media types are: bokeh table CSV PNG JPEG MP3 MP4 Here's an example for how to create a full result in Python: def append_output(df, title, renderable, downloadable): js, div = make_my_plot(df, title) renderable.append( { \"media_type\": \"bokeh\", \"title\": title, \"data\": { \"javascript\": js, \"html\": div } } ) downloadable.append( { \"media_type\": \"CSV\", \"title\": title, \"data\": df.to_csv() } ) downloadable = [] renderable = [] append_output(my_df, \"My results\", renderable, downloadable) append_output(my_other_df, \"My other results\", renderable, downloadable) A full example can be found in the Matchups package . Examples bokeh JSON format: { \"media_type\": \"bokeh\", \"title\": \"My Bokeh Plot\", \"data\": { \"html\": \"<div>...</div>\", \"js\": \"<script>...</script>\" } } Python example: from bokeh.plotting import figure from bokeh.embed import components # see: https://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#getting-started # prepare some data x = [1, 2, 3, 4, 5] y = [6, 7, 2, 4, 5] # create a new plot with a title and axis labels p = figure(title=\"simple line example\", x_axis_label='x', y_axis_label='y') # add a line renderer with legend and line thickness p.line(x, y, legend=\"Temp.\", line_width=2) # get the results js, div = components(p) output = { \"media_type\": \"bokeh\", \"title\": \"simple line example\", \"data\": { \"html\": div, \"js\": js } } table JSON format: { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": \"<table>...</table>\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) table = df.to_html() output = { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": table } CSV JSON format: { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": \"comma,sep,values\\n\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) csv = df.to_csv() output = { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": csv }","title":"Ouptuts"},{"location":"publish/outputs/#outputs","text":"Projects should return outputs that are in the following format: { \"renderable\": [ { \"media_type\": \"PNG\", \"title\": \"My PNG\", \"data\": \"picture bytes here...\" } ], \"downloadable\": [ { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": \"comma,sep,values\\n\" } ] } There are two categories of outputs: \"renderable\" and \"downloadable.\" Renderable outputs will be displayed on the outputs page while downloadable outputs are saved by the user as a zipfile. These categories are represented as the two top-level members in the JSON structure above. They point to a List of Output Objects . Each Output Object has three members: media_type , title , and data . Supported media types are: bokeh table CSV PNG JPEG MP3 MP4 Here's an example for how to create a full result in Python: def append_output(df, title, renderable, downloadable): js, div = make_my_plot(df, title) renderable.append( { \"media_type\": \"bokeh\", \"title\": title, \"data\": { \"javascript\": js, \"html\": div } } ) downloadable.append( { \"media_type\": \"CSV\", \"title\": title, \"data\": df.to_csv() } ) downloadable = [] renderable = [] append_output(my_df, \"My results\", renderable, downloadable) append_output(my_other_df, \"My other results\", renderable, downloadable) A full example can be found in the Matchups package .","title":"Outputs"},{"location":"publish/outputs/#examples","text":"","title":"Examples"},{"location":"publish/outputs/#bokeh","text":"JSON format: { \"media_type\": \"bokeh\", \"title\": \"My Bokeh Plot\", \"data\": { \"html\": \"<div>...</div>\", \"js\": \"<script>...</script>\" } } Python example: from bokeh.plotting import figure from bokeh.embed import components # see: https://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#getting-started # prepare some data x = [1, 2, 3, 4, 5] y = [6, 7, 2, 4, 5] # create a new plot with a title and axis labels p = figure(title=\"simple line example\", x_axis_label='x', y_axis_label='y') # add a line renderer with legend and line thickness p.line(x, y, legend=\"Temp.\", line_width=2) # get the results js, div = components(p) output = { \"media_type\": \"bokeh\", \"title\": \"simple line example\", \"data\": { \"html\": div, \"js\": js } }","title":"bokeh"},{"location":"publish/outputs/#table","text":"JSON format: { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": \"<table>...</table>\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) table = df.to_html() output = { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": table }","title":"table"},{"location":"publish/outputs/#csv","text":"JSON format: { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": \"comma,sep,values\\n\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) csv = df.to_csv() output = { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": csv }","title":"CSV"}]}